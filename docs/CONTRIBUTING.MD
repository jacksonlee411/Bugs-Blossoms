# Contributing Guide

## âš™ï¸ Prerequisites

Ensure these tools are installed before you begin:

- [Go v1.24.10](https://golang.org/doc/install)
- [Air v1.61.5](https://github.com/air-verse/air#Installation) - Hot-reloading
- [Docker v27.2.0](https://docs.docker.com/get-docker/) - Containerization
- [Templ v0.3.857](https://templ.guide/) - Templating
- [TailwindCSS v3.4.13](https://tailwindcss.com/docs/installation) - Styling
- [golangci-lint 1.64.8](https://golangci-lint.run/welcome/install/) - Linting
- [cloudflared](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/) - Tunnel (Optional)

### Windows Setup

1. **Go**: Download from [golang.org](https://golang.org/doc/install), install, and verify with `go version`

2. **Air**:
   ```cmd
   go install github.com/air-verse/air@v1.61.5
   ```
   Add `%USERPROFILE%\go\bin` to your PATH

3. **Docker Desktop**: Download from [docker.com](https://docs.docker.com/desktop/install/windows-install/), enable WSL 2 during installation

4. **Templ**:
   ```cmd
   go install github.com/a-h/templ/cmd/templ@v0.3.857
   ```

5. **TailwindCSS**: Using npm (requires Node.js):
   ```cmd
   npm install -g tailwindcss
   ```
   Or with standalone executable:
   ```cmd
   curl.exe -sLO https://github.com/tailwindlabs/tailwindcss/releases/v3.4.13/download/tailwindcss-windows-x64.exe
   rename tailwindcss-windows-x64.exe tailwindcss.exe
   ```

6. **golangci-lint**:
   ```cmd
   curl.exe -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.ps1 | powershell -Command -
   ```

7. **cloudflared**
   ```cmd
   winget install --id Cloudflare.cloudflared
   ```

## ğŸ› ï¸ Development Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/iota-uz/iota-sdk.git
   cd iota-sdk
   ```

2. **Create env file**:
   ```bash
   cp .env.example .env
   ```
   Windows: `copy .env.example .env`

3. **Install dependencies**:
   ```bash
   make deps
   ```
   Windows: If `make` is unavailable, install via [GnuWin32](http://gnuwin32.sourceforge.net/packages/make.htm) or use [Git Bash](https://gitforwindows.org/)

4. **Run PostgreSQL**:
   ```bash
   make db local
   ```
   Ensure Docker is running before executing this command

5. **Apply migrations**:
   ```bash
   make db migrate up && make db seed
   ```

6. **Run TailwindCSS in watch mode** (new terminal):
   ```bash
   make css watch
   ```

7. **Start development server**:
   ```bash
   air
   ```

8. **Access the application**:
   - Web app: [http://localhost:8080](http://localhost:8080)
   - Login credentials:
     - Email: `test@gmail.com`
     - Password: `TestPass123!`
   - GraphQL: [http://localhost:3200/query](http://localhost:3200/query)

### Development Tools Manager

For a more convenient development experience, use the DevHub TUI tool to manage all development services from a single interface:

```bash
make devtools
```

The DevHub allows you to:
- Start/stop the development server
- Toggle template file watching (`templ generate --watch`)
- Toggle CSS file watching (TailwindCSS watch mode)
- Manage local PostgreSQL database
- Start/stop Cloudflare tunnel

Navigate with arrow keys, toggle services with Space/Enter, and quit with 'q'.

## âœ… Quality Gates & Local Checks

All pushes to `main`/`dev` and every pull request run `.github/workflows/quality-gates.yml`. The workflow enforces Go formatting/linting/testing on Go 1.24.10, regenerates templ/Tailwind artifacts only when presentation files change, checks locale JSON diffs, and runs PostgreSQL 17 + Redis-backed migrations with a `migrate.log` artifact.

| When you changeâ€¦ | CI step | Run locally before pushing |
| --- | --- | --- |
| Any Go code | `go fmt ./...`, `go vet ./...`, `make check lint`, `go test -v ./...` | `go fmt ./... && go vet ./... && make check lint && make test` |
| `.templ`, `tailwind.config.js`, or `modules/**/presentation/assets/**` | `make generate`, `make css`, `git status --short` | `make generate && make css` then `git status --short` |
| `modules/**/presentation/locales/**/*.json` | `make check tr` | `make check tr` |
| `migrations/**` or `modules/**/infrastructure/persistence/schema/**` | PostgreSQL/Redis services + `make db migrate up/down` + `make db seed` (logs stored in `migrate.log`) | `make db migrate up && make db seed` (optionally `make db migrate down` to smoke test) |
| `sqlc.yaml`, `modules/hrm/infrastructure/sqlc/**`, `modules/hrm/infrastructure/persistence/**/*.sql`, `scripts/db/export_hrm_schema.sh`, `docs/dev-records/hrm-sql-inventory.md` | `make sqlc-generate` + `git status --short` via `hrm-sqlc` filter | `scripts/db/export_hrm_schema.sh` + `make sqlc-generate` + `git status --short` |

> **è¯´æ˜**ï¼šFinance æ¨¡å—ï¼ˆ`modules/finance/**`ï¼‰çš„è‡ªåŠ¨åŒ–æµ‹è¯•æš‚æ—¶åœç”¨ï¼Œå¦‚ä¿®æ”¹è¯¥æ¨¡å—è¯·è‡ªè¡Œè¿è¡Œ `go test ./modules/finance/...` å¹¶åœ¨ PR æè¿°ä¸­é™„ä¸Šç»“æœã€‚

Running the matching commands locally ensures your branch passes the `quality-gates` check before you open a PR.

### HRM sqlc å˜æ›´

- HRM ä»»ä½• SQL/è¿ç§»è°ƒæ•´éƒ½å¿…é¡»å…ˆè¿è¡Œ `scripts/db/export_hrm_schema.sh` æ›´æ–° `modules/hrm/infrastructure/sqlc/schema.sql`ï¼Œéšåæ‰§è¡Œ `make sqlc-generate`ï¼ˆ`make generate` ä¼šè‡ªåŠ¨è°ƒç”¨ï¼‰ï¼Œä»¥ä¾¿é‡å»º `modules/hrm/infrastructure/sqlc/**`ã€‚
- ç”Ÿæˆæ­¥éª¤ä¹Ÿä¼šåœ¨ CI ä¸­é€šè¿‡ `hrm-sqlc` è¿‡æ»¤å™¨è‡ªåŠ¨æ‰§è¡Œï¼›è‹¥è¿˜æœ‰æœªæäº¤çš„ç”Ÿæˆæ–‡ä»¶ï¼Œå·¥ä½œæµä¼šå¤±è´¥ã€‚
- è¯·åŒæ­¥ç»´æŠ¤ `docs/dev-records/hrm-sql-inventory.md`ï¼Œè®©è¯„å®¡èƒ½å¿«é€Ÿå®šä½ SQL å˜åŠ¨ã€‚

### HRM Atlas + Goose

- HRM è¡¨ç»“æ„ä»¥ `modules/hrm/infrastructure/atlas/schema.hcl` ä¸ºå”¯ä¸€å£°æ˜å¼æ¥æºï¼ŒAtlas é…ç½®ä½äºä»“åº“æ ¹ç›®å½• `atlas.hcl`ã€‚
- æ–°è¿ç§»ç”± `atlas migrate diff --env dev --dir file://migrations/hrm --to file://modules/hrm/infrastructure/atlas/schema.hcl` ç”Ÿæˆï¼›Dry-run å¯é€šè¿‡ `make db plan`ï¼ˆå†…éƒ¨è°ƒç”¨ `atlas migrate diff --dry-run`ï¼‰ã€‚
- ä½¿ç”¨ `HRM_MIGRATIONS=1 make db migrate up` è§¦å‘ `scripts/db/run_goose.sh`ï¼ŒGoose ä¼šå¯¹ `migrations/hrm/changes_<unix>.{up,down}.sql` è¿›è¡Œ apply/rollbackã€‚  
  - å›æ»šï¼š`GOOSE_STEPS=1 make db migrate down HRM_MIGRATIONS=1`  
  - redoï¼š`GOOSE_STEPS=1 make db migrate redo HRM_MIGRATIONS=1`  
  - çŠ¶æ€ï¼š`make db migrate status HRM_MIGRATIONS=1`
- è¿ç§»æ‰§è¡Œå®Œæ¯•åå¿…é¡»è¿è¡Œ `scripts/db/export_hrm_schema.sh SKIP_MIGRATE=1 && make sqlc-generate`ï¼Œä¿æŒ schema/sqlc ä¸æ•°æ®åº“ä¸€è‡´ã€‚
- `make db lint` ä¼šæ‰§è¡Œ `atlas migrate lint --env ci --git-base origin/main`ï¼ŒCI é€šè¿‡æ–°çš„ `hrm-atlas` è¿‡æ»¤å™¨å¼ºåˆ¶è¯¥æ­¥éª¤ï¼›ä»»ä½•ç¼ºå¤±çš„è¿ç§»æˆ– `atlas.sum`/`schema.hcl` æ¼‚ç§»éƒ½ä¼šå¯¼è‡´ PR å¤±è´¥ã€‚
- æ‰€æœ‰ Atlas / Goose æ¼”ç»ƒè¯·å†™å…¥ `docs/dev-records/DEV-PLAN-011-HRM-ATLAS-POC.md`ï¼Œç¡®ä¿æœ‰å¯è¿½è¸ªçš„â€œå‘½ä»¤ â†’ ç»“æœâ€è®°å½•ã€‚

## ğŸ§ª Running Tests

### E2E Testing

The project includes Playwright end-to-end tests that run against a separate database to isolate test data from development data.

#### Setup:
1. **Create and prepare e2e database**:
   ```bash
   make e2e setup
   ```

2. **Start e2e server** (in a separate terminal):
   ```bash
   make e2e server
   ```
   This starts the server on port 3201 connected to the e2e database (`iota_erp_e2e`).

3. **Run tests**:
   ```bash
   # All tests
   make e2e test

   # Interactive mode
   make e2e run

   # Or directly with npm
   cd e2e/
   pnpm run test:headed
   ```

#### Available E2E Commands:
- `make e2e setup` - Create e2e database, run migrations, and seed
- `make e2e reset` - Drop and recreate e2e database with fresh data
- `make e2e server` - Start server on port 3201 (connected to e2e database)
- `make e2e test` - Run all e2e tests
- `make e2e run` - Open Playwright UI mode
- `make e2e clean` - Drop e2e database

#### Important Notes:
- E2E tests use a separate database (`iota_erp_e2e`) from development (`iota_erp`)
- E2E server runs on port 3201, development server runs on port 3200
- Always run `make e2e server` before running tests to ensure server connects to correct database
- Configuration files: `/e2e/.env.e2e`, `/e2e/playwright.config.ts`

## ğŸ“š Documentation

Generate code documentation:

```bash
# For entire project
make docs

# With specific options
go run cmd/command/main.go doc -dir [directory] -out [output file] [-recursive] [-exclude "dir1,dir2"]
```

Options:
- `-dir`: Target directory (default: current directory)
- `-out`: Output file path (default: DOCUMENTATION.md)
- `-recursive`: Process subdirectories
- `-exclude`: Skip specified directories (comma-separated)

## Explicitly Name Database Constraints

When defining or altering table schemas in `.sql` files that are processed by the `schema/collector` (both in `db/migrations/` and embedded module schemas):

## IMPORTANT NOTE:
Migration tool only supports UNIQUE constraints (other constraints are not yet supported). Keep this in mind when mutating schemas.
Changes in configuration such as altering varchar(255) to varchar(500) or changing datetime from null to now() are not handled.
TODO list of limitations.

**```All constraints (PRIMARY KEY, UNIQUE, FOREIGN KEY, CHECK) MUST be explicitly named using the CONSTRAINT <constraint_name> syntax.```**

### Reasoning:

The `schema/collector` tool automatically generates `Up` and `Down` migration scripts by comparing schema states. To create correct `DROP CONSTRAINT` commands (especially critical for `Down` migrations and for modifying existing constraints), the tool relies on predictable constraint names. Database auto-generated names are inconsistent and difficult for the tool to determine reliably, leading to potential migration failures. Explicit naming ensures that schema comparisons and generated migrations are accurate and robust.

### Recommended Naming Convention:

Please use the following convention for consistency:

`<table>_<column(s)>_<type_suffix>`

**Suffixes:**

* `_pkey` for Primary Keys
* `_key` for Unique Constraints (please be consistent within the project)
* `_fk` for Foreign Keys
* `_check` for Check Constraints

**Note:** For multi-column constraints, include relevant column names separated by underscores if feasible, or provide a meaningful description.

This documentation provides context for LLMs working on the IOTA-SDK project.

## â“ Known Issues and Troubleshooting

### Linting Issues

Do not run
```shell
golangci-lint run --fix
```
It will break the code.

When facing an error like this:
```
WARN [runner] Can't run linter goanalysis_metalinter: buildssa: failed to load package : could not load export data: no
export data for "github.com/iota-uz/iota-sdk/modules/core/domain/entities/expense_category"
```
Try running:
```shell
go mod tidy
```

### Windows Setup Issues

1. **Make commands fail**:
   - Install via [GnuWin32](http://gnuwin32.sourceforge.net/packages/make.htm)
   - Add installation directory to PATH
   - Or use Git Bash which includes Make

2. **Docker issues**:
   - Ensure WSL 2 is properly configured
   - Run `wsl --update` as administrator
   - Restart Docker Desktop

3. **Air hot-reloading problems**:
   - Verify Air is in your PATH
   - Check for `.air.toml` configuration
   - Try `air init` to create new configuration

4. **PostgreSQL connection issues**:
   - Ensure Docker is running
   - Check container status: `docker ps`
   - Verify database credentials in `.env`

### Start cloudflare tunnel

To intercept incoming traffic from third-party systems, such as payment gateways, you can use a Cloudflare Tunnel.

Try running:
```bash
make tunnel
```

## ğŸ¤– Using AI

### Claude Code Setup

1. **Install Claude Code**:
   ```bash
   npm install -g @anthropic-ai/claude-code
   ```
   
   See [Claude Code docs](https://docs.anthropic.com/en/docs/claude-code/overview) for more details.

2. **Add MCP servers**:
   ```bash
   # Context7 (documentation and API references)
   claude mcp add -s user --transport http context7 https://mcp.context7.com/mcp

   # Puppeteer (browser automation)
   claude mcp add -s user puppeteer -e 'PUPPETEER_LAUNCH_OPTIONS={"headless":false,"args":["--remote-debugging-port=9222","--remote-debugging-address=127.0.0.1","--user-data-dir=/tmp/mcp-profile","--no-sandbox","--disable-setuid-sandbox"]}' -- npx -y puppeteer-mcp-server@0.7.2 --stdio

   # Go documentation (install first)
   go install github.com/mrjoshuak/godoc-mcp@latest
   claude mcp add -s user godoc-mcp $(go env GOPATH)/bin/godoc-mcp
   
   # Code Indexer (semantic code search)
   # Requires OPENAI_API_KEY and MILVUS_TOKEN environment variables
   # Contact team lead for MILVUS_TOKEN if you don't have it
   claude mcp add code-indexer -e OPENAI_API_KEY=$OPENAI_API_KEY -e MILVUS_ADDRESS=https://in03-2c743230eb1daa2.serverless.gcp-us-west1.cloud.zilliz.com -e MILVUS_TOKEN=$MILVUS_TOKEN -- npx @code-indexer/mcp@latest
   ```

3. **Usage**:
   ```bash
   # List configured MCP servers
   claude mcp list
   
   # Start Claude Code (MCP auto-enabled)
   claude
   ```

### Code Indexing

The repository uses automated code indexing for semantic search. When you push changes, the GitHub Actions workflow automatically indexes the codebase using the `@code-indexer/core` package with OpenAI embeddings.

## ğŸ¤ Communication Guidelines

Contributors should close conversations when complete. Reviewers may reopen if needed.

For additional help, see our [FAQ](./FAQ.md) or open a GitHub issue.
